{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "from tqdm import trange, tqdm\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from livedoor_datasets import LivedoorDataset\n",
    "from model import Model\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from transformers import LlamaTokenizer, BatchEncoding\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from accelerate import Accelerator\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:53:09.512040503Z",
     "start_time": "2023-11-21T05:53:05.397123962Z"
    }
   },
   "id": "551c4279bf5e8d6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "lr = 5e-10\n",
    "max_seq_len = 128\n",
    "seed = 42\n",
    "batch_size = 1\n",
    "epochs = 2\n",
    "model_name = \"stabilityai/japanese-stablelm-base-alpha-7b\",\n",
    "tokenizer_name = \"novelai/nerdstash-tokenizer-v1\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:53:09.514795861Z",
     "start_time": "2023-11-21T05:53:09.513246761Z"
    }
   },
   "id": "15dea4c04aa2c187"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "taglist = utils.read_taglist()\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=tokenizer_name,\n",
    "    additional_special_tokens=['__'],\n",
    "    max_seq_len = max_seq_len,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:53:10.528456652Z",
     "start_time": "2023-11-21T05:53:09.520098905Z"
    }
   },
   "id": "e14de2566b585654"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(datalist) -> BatchEncoding:\n",
    "    inputs = tokenizer(\n",
    "        text=[text for (text, _) in datalist],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_seq_len,\n",
    "    )\n",
    "    labels = []\n",
    "    for _, tag in datalist:\n",
    "        labels.append(taglist.index(tag))\n",
    "    labels = torch.LongTensor(labels)\n",
    "    return BatchEncoding({ **inputs, \"labels\": labels })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:53:10.551234137Z",
     "start_time": "2023-11-21T05:53:10.537322358Z"
    }
   },
   "id": "5a323bfb48da889a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def dataloaders():\n",
    "    dataset = LivedoorDataset()\n",
    "    all_num = len(dataset)\n",
    "    train_num = int(all_num * 0.5)\n",
    "    val_num = int(all_num - train_num)\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_num, val_num])\n",
    "    train_dataloader = create_dataloader(train_dataset)\n",
    "    val_dataloader = create_dataloader(val_dataset)\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def create_dataloader(dataset):\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:53:10.568634309Z",
     "start_time": "2023-11-21T05:53:10.546234709Z"
    }
   },
   "id": "db01a19652b414b2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "530eb3a22c834c0cb3b4cdb226a2fe8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = dataloaders()\n",
    "num_steps = len(train_dataloader)\n",
    "model = Model(num_labels=len(taglist))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:54:28.949991290Z",
     "start_time": "2023-11-21T05:53:10.560481337Z"
    }
   },
   "id": "762711a707669984"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# dictをtnsorに変換する。textとlabelsにする\n",
    "def train(model:Model, train_dataloader, val_dataloader):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    model.train()\n",
    "    best_val_f1 = 0\n",
    "    best_state_dict = model.state_dict()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_steps,\n",
    "        num_training_steps=num_steps * epochs\n",
    "    )\n",
    "\n",
    "    model, train_dataloader, val_dataloader, optimizer, lr_scheduler = accelerator.prepare(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        optimizer,\n",
    "        lr_scheduler,\n",
    "    )\n",
    "\n",
    "    for epoch in trange(epochs, dynamic_ncols=True):\n",
    "        for batch in tqdm(train_dataloader, total=len(train_dataloader), dynamic_ncols=True):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            loss = output.loss\n",
    "            print(f\"------------------------- loss:{loss}\")\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        model.eval()\n",
    "        (accuracy, f1, precision, recall) = evaluate(model, val_dataloader)\n",
    "\n",
    "        # if f1 > best_val_f1:\n",
    "        #    best_val_f1 = f1\n",
    "        #    best_state_dict = model.state_dict()\n",
    "\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    torch.save(best_state_dict, \"model.pth\")\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    val_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), dynamic_ncols=True, leave=False):\n",
    "        output = model(**batch)\n",
    "        batch_size = batch.input_ids.size(0)\n",
    "        loss = output.loss.item() * batch_size\n",
    "        pred_labels += output.logits.argmax(dim=-1).tolist()\n",
    "        val_labels += batch.labels.tolist()\n",
    "        total_loss += loss\n",
    "\n",
    "        accuracy = accuracy_score(pred_labels, val_labels)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            val_labels,\n",
    "            pred_labels,\n",
    "            average=\"macro\",\n",
    "            zero_division=0,\n",
    "        )\n",
    "        return (accuracy, f1, precision, recall)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:54:28.963908392Z",
     "start_time": "2023-11-21T05:54:28.960467307Z"
    }
   },
   "id": "92f2030783c7950a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos: torch.float16\n",
      "logits tensor([[ 0.5723,  0.5649, -1.1914,  0.2781, -0.5488,  1.8779,  0.1324,  0.2430,\n",
      "          0.1755]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<MmBackward0>)\n",
      "loss: tensor(2.4863, device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<NllLossBackward0>)\n",
      "------------------------- loss:2.486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/50 [00:03<02:46,  3.39s/it]\u001B[A/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Error detected in LogSoftmaxBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_76834/1403165015.py\", line 1, in <module>\n",
      "    train(model, train_dataloader, val_dataloader)\n",
      "  File \"/tmp/ipykernel_76834/2255213923.py\", line 25, in train\n",
      "    output = model(**batch)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kuninori/dev/llm-classfication/model.py\", line 62, in forward\n",
      "    loss = self.loss_fn(logits, labels)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py\", line 1179, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/home/kuninori/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/nn/functional.py\", line 3053, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  2%|▏         | 1/50 [00:03<03:04,  3.77s/it]\n",
      "  0%|          | 0/2 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos: torch.float16\n",
      "logits tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
      "loss: tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
      "------------------------- loss:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'LogSoftmaxBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 28\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_dataloader, val_dataloader)\u001B[0m\n\u001B[1;32m     26\u001B[0m loss \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m------------------------- loss:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m \u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     30\u001B[0m lr_scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/dev/llm-classfication/venv/lib/python3.10/site-packages/accelerate/accelerator.py:1989\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[0;34m(self, loss, **kwargs)\u001B[0m\n\u001B[1;32m   1987\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1988\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1989\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/llm-classfication/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Function 'LogSoftmaxBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:54:33.565862531Z",
     "start_time": "2023-11-21T05:54:28.965689737Z"
    }
   },
   "id": "989c52d4f3e20064"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T05:54:33.578212582Z",
     "start_time": "2023-11-21T05:54:33.569319854Z"
    }
   },
   "id": "52a2d3e738495ede"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
